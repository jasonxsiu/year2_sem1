---
title: "MLR_assignment"
output: html_document
---

The model is to estimate :
  - how strong the relationship is between Clout (dependent var) and other variables (independent var)
  - the expected Clout value at certain levels of WC,Analytic,Clout,Authentic,WPS,i,we,you,they and so on
  
Assumptions of multiple linear regression : 
```{r import-lib, message = FALSE, warning = FALSE}
library(tidyverse)
library(lubridate)
library(corrgram)
```
Read the data
```{r read data}
rm(list = ls())
set.seed(31084222)
data <-  read.csv("C:/Users/sjsa3/Desktop/Shared_with_Mac/year2_sem1/FIT3152/Assignment_FIT3152_2021/webforum.csv")

data <- data[sample(nrow(data),20000),] #20000 rows
```
Clean the data

```{r lib-for-MLR, message=F}
library(Hmisc)
library(psych)
library(car)
```


```{r}
data$Date <- as.Date(data$Date)
data

#check if there is any missing values
sum(is.na(data))

data_tidy <- data %>%
  mutate(month = month(Date,  label = TRUE, abbr = TRUE), 
         wday = wday(Date, label = TRUE, abbr = TRUE, week_start = 1),
         year = year(Date),
         day = day(Date),
         hour = hm(Time))
data_tidy

#scale the numeric data
data_tidy_scale <- data.frame( scale(data_tidy[,5:19],center=TRUE,scale=TRUE) )

df <-  data_tidy_scale %>% select(WC,Analytic,Clout,Authentic,WPS,i,we,you,they,number,affect, posemo,negemo, anx)
```


```{r }

### Develop a linear model
#   The model will be built using the training sample of the data
#   The model will be validated using the validation sample of the data

# Split data into training and validation samples
# We will use (train.size)% for training and (100-train.size)% for validation
train.size <- 0.8 
train.index <- sample.int(length(df$Authentic), round(length(df$Authentic) * train.size))
train.sample <- df[train.index,]
valid.sample <- df[-train.index,]


### Multiple regression model utilises a simple formula:
#    Price = B0 + B1 x Horsepower + B2 x Curb.weight + B3 x City.mpg + ...
#
# We will perform additional tests on the training data

# We will use a stepwise selection of variables by backwards elimination
# We will consider all candidate variables and eliminate one at the time
# As we have quite a few variables will not consider variable interaction at this stage, i.e.
#   Price ~ Horsepower*Curb.weight*City.mpg*Peak.rpm*Num.of.doors

### Fit the model (1)
fit <- lm(affect ~ posemo +negemo+anx, data=train.sample)
summary(fit) # R2=81%, F=139.5
# plot(fit)
```

```{r elim-xtreme-1}
# crPlots(fit)

# Eliminate extreme values
cutoff <- 4/((nrow(train.sample)-length(fit$coefficients)-2)) # Cook's D plot, cutoff as 4/(n-k-1)
plot(fit, which=4, cook.levels=cutoff)                        # identify D values > cutoff

plot(fit, which=5, cook.levels=cutoff)
train.sample <- train.sample[-which(rownames(train.sample)    # Row names discovered in 2 rounds
    %in% c("19998", "5379", "1755")),]  
```
After refiting the model 1
```{r refit1}
fit <- lm(affect ~ posemo+negemo+anx, data=train.sample)
summary(fit) # R2=81%, F=139.5
```
```{r elim-xtreme-2}
# crPlots(fit)

# Eliminate extreme values
cutoff <- 4/((nrow(train.sample)-length(fit$coefficients)-2)) # Cook's D plot, cutoff as 4/(n-k-1)
plot(fit, which=4, cook.levels=cutoff)                        # identify D values > cutoff

train.sample <- train.sample[-which(rownames(train.sample)    # Row names discovered in 2 rounds
    %in% c("14068", "4561", "5739")),]  
```
 After refiting the model 2
```{r refit2}
fit <- lm(affect ~ posemo+negemo+anx, data=train.sample)
summary(fit)$adj.r.squared # R2=81%, F=139.5
```
```{r elim-xtreme-3}
# crPlots(fit)

# Eliminate extreme values
cutoff <- 4/((nrow(train.sample)-length(fit$coefficients)-2)) # Cook's D plot, cutoff as 4/(n-k-1)
plot(fit, which=4, cook.levels=cutoff)                        # identify D values > cutoff

train.sample <- train.sample[-which(rownames(train.sample)    # Row names discovered in 2 rounds
    %in% c("2331", "16348", "19390")),]  
```
 After refiting the model 3
```{r refit3}
fit <- lm(affect ~ posemo+negemo+anx, data=train.sample)
summary(fit)$adj.r.squared # R2=81%, F=139.5
```

```{r Check-multi-collinearity}

# Check for multi-collinearity with Variance Inflation Factor
# Correlated: none VIF=1, moderately 1<VIF<5, ** highly 5<VIF<10, ...
vif(fit)
```
```{r rm-var-basedOn-pvalue}
summary(fit)
#eliminate the p-value lower than .05
#rm number
fit <- lm(affect ~ posemo+negemo+anx, data=train.sample)
summary(fit) # R2=81%, F=139.5



```


Clout ~ WC+Authentic+Analytic+WPS+i+we+you+they

```{r}
### VIF, F-ratio and p-values say it is good, so no need to do anything else

##### Now evaluate the final linear model
#     Find all predicted values for both a training set and a validation set
train.sample$Pred.affect <- predict(fit, 
    newdata = train.sample %>% select (posemo,negemo,anx))
valid.sample$Pred.affect <- predict(fit, 
    newdata = subset(valid.sample, select=c(posemo,negemo,anx)))

# The theoretical model performance is defined here as R-Squared
summary(fit)
```


```{r}

# Check how good is the model on the training set - correlation^2, RME and MAE
train.corr <- round(cor(train.sample$Pred.affect , train.sample$affect ), 2)
train.RMSE <- round(sqrt(mean((10 ^ train.sample$Pred.affect  - 10 ^ train.sample$affect )^2)))
train.MAE <- round(mean(abs(10 ^ train.sample$Pred.affect  - 10 ^ train.sample$affect )))
c(train.corr^2, train.RMSE, train.MAE)
# With all prep is: 0.8836 2670.0000 1759.0000 / As above
# Do nothing was:   0.7225 3997.0000 2676.0000 / See previous lesson

# Check how good is the model on the validation set - correlation^2, RME and MAE
valid.corr <- round(cor(valid.sample$Pred.affect , valid.sample$affect ), 2)
valid.RMSE <- round(sqrt(mean((10 ^ valid.sample$Pred.affect  - 10 ^ valid.sample$affect )^2)))
valid.MAE <- round(mean(abs(10 ^ valid.sample$Pred.affect  - 10 ^ valid.sample$affect )))
c(valid.corr^2, valid.RMSE, valid.MAE)
# With all prep is: 0.7396 5723.0000 3334.0000 / As above
# Do nothing was:   0.6889 4927.0000 3208.0000 / See previous lesson

# Small data set - Cross-validation should be used, but vars selection needs to be auto!
# These results and the model should now be interpreted

```

=============================================VISUALISATION=====================================================


```{r}
avPlots(fit, main = "The partial regression on affect given posemo and negemo")
```

https://stats.stackexchange.com/questions/125561/what-does-an-added-variable-plot-partial-regression-plot-explain-in-a-multiple

https://www.youtube.com/watch?v=QX028TaLFO0

The added variable plot gives you two dimensional perspectives for any number of variables. It may be particularly revealing in higher dimensions. One often finds revealing patterns in the residuals which were not at all obvious in the observed Y. â€“

```{r 3d-scatterchart}
 library(scatterplot3d)
library(rgl)
train.sample
sur <-scatter3d(train.sample$posemo,train.sample$negemo,train.sample$affect,pch=16)
fit <- lm(affect ~ posemo+negemo, data=train.sample)
sur$plane3d(fit)
plot3d(train.sample$posemo,train.sample$affect ,train.sample$negemo,type = "p")
```

