import the needed lib
```{r include=F}
library(tidyverse)
library(simputation) #imputation
library(naniar)
library(lubridate)
library(tidymodels)
```


```{r include=F}
library(tree)
library(skimr) # data exploratory
library(psych)  #for general functions
```


```{r include=F}
library(e1071) #Na√Øve Bayes
library(ROCR)
library(pROC)
```

read file
```{r read-file}
rm(list = ls()) 
WAUS <- read.csv("C:/Users/sjsa3/Desktop/Shared_with_Mac/year2_sem1/FIT3152/Assignment 2/data.csv")
WAUS <- WAUS %>% filter(CloudTomorrow != "NA") #remove the rows in which the value of CloudTmr is NA
L <- as.data.frame(c(1:49)) 
set.seed(31084222) # Your Student ID is the random seed 
L <- L[sample(nrow(L), 10, replace = FALSE),] # sample 10 locations ====
WAUS <- WAUS[(WAUS$Location %in% L),] 
WAUS <- WAUS[sample(nrow(WAUS), 2000, replace = FALSE),] # sample 2000 rows 
```
clean the data 
```{r factor-variables}
WAUS$WindGustDir = factor(WAUS$WindGustDir)
WAUS$WindDir9am = factor(WAUS$WindDir9am)
WAUS$WindDir3pm = factor(WAUS$WindDir3pm)
WAUS$Location = factor(WAUS$Location)
WAUS$RainToday = factor(WAUS$RainToday)
WAUS$CloudTomorrow = factor(WAUS$CloudTomorrow)
```



impute the data
```{r}
#date format
WAUS$Date = ""
WAUS$Day = as.character(WAUS$Day)
WAUS$Month = as.character(WAUS$Month)
WAUS$Year = as.character(WAUS$Year)
WAUS$Date =paste(WAUS$Year,"-" ,WAUS$Month,"-", WAUS$Day)
WAUS$Date = ymd(WAUS$Date)

WAUS= WAUS %>% arrange(Date)
           WAUS$MinTemp = impute_mean( WAUS$MinTemp) 
        WAUS$MaxTemp= impute_mean( WAUS$MaxTemp) 
       WAUS$Rainfall=  impute_mean( WAUS$Rainfall) 
       WAUS$Evaporation=  impute_mean( WAUS$Evaporation) 
      WAUS$Sunshine=   impute_mean( WAUS$Sunshine) 
      WAUS$WindGustSpeed=   impute_mean( WAUS$WindGustSpeed) 
       WAUS$WindSpeed9am=  impute_mean( WAUS$WindSpeed9am) 
       WAUS$WindSpeed3pm=  impute_mean( WAUS$WindSpeed3pm) 
      WAUS$Humidity9am=   impute_mean( WAUS$Humidity9am) 
      WAUS$Humidity3pm=   impute_mean( WAUS$Humidity3pm) 
      WAUS$Pressure9am =   impute_mean( WAUS$Pressure9am) 
     WAUS$Pressure3pm =   impute_mean( WAUS$Pressure3pm) 
         WAUS$Temp9am =   impute_mean( WAUS$Temp9am) 
     WAUS$Temp3pm =   impute_mean( WAUS$Temp3pm)  

     WAUS = WAUS %>% drop_na()
```

Explore data
```{r explore-data include=FALSE}
describe(WAUS)
skim(WAUS)
```

Since we are predicting the cloudiness, there is no use of Location, Date, thus removing them 
```{r}
WAUS <- WAUS  %>% select(-Location,-Day,-Year,-Month,-Date)
```


set-seed
```{r set-seed}
 

 set.seed(31084222) #Student ID as random seed 
 train.row = sample(1:nrow(WAUS), 0.7*nrow(WAUS)) 
 WAUS.train = WAUS[train.row,] 
 WAUS.test = WAUS[-train.row,] 

 
```

data pre-processing 
```{r}
CloudReceipe <- recipe(CloudTomorrow ~ ., data = WAUS.train) %>% 
        step_corr(all_numeric())%>% #remove the correlated variables
        step_normalize(all_numeric()) %>% #normalise all numberic data
        step_dummy(all_nominal(), -all_outcomes())%>% #change factored variables to variables
        step_zv(all_numeric()) %>% #remove variables with 0 variance
        step_medianimpute(all_numeric(), -all_outcomes())  %>% # impute the missing values
        prep()#process it

#have a look at the Receipe
 juice(CloudReceipe)

```
===============================Decision tree
```{r DT}
fit = tree(CloudTomorrow ~ ., data = WAUS.train)
summary(fit)
plot(fit)
text(fit)

#https://www.guru99.com/r-decision-trees.html#5
# library(rpart)
# library(rpart.plot)
# fit <- rpart(CloudTomorrow~., 
#              data = WAUS.train,
#              method = 'class')
# rpart.plot(fit, extra = 106)


```


```{r performance}
precision <- function(x) {
        prec <-  (x[1,3]) / (x[1,3] + x[2,3])
        return( prec )
}

accuracy <-  function(x) {
        acc <-  (( x[1,3] + x[4,3])  /  sum(x[,3]) )
        return( acc )
}

 
recall <-  function(x) {
        rec <-  (x[1,3])  /   (x[1,3] + x[3,3])
        return( rec )
}
```

predict
```{r test-DT}
fit.predict <- predict(fit, WAUS.test,type = "vector")
# x <- as.tibble(table(actual = WAUS.test$CloudTomorrow, predicted = fit.predict) )
# precision(x)
# accuracy(x)
# recall(x)



#prune it 
testfit =cv.tree(fit,FUN=prune.misclass)
prune.fit = prune.misclass(fit, best=3)
fit.predict <- predict(prune.fit, WAUS.test,type = "vector")
# x <- as.tibble(table(actual = WAUS.test$CloudTomorrow, predicted = fit.predict) )
# precision(x)
# accuracy(x)
# recall(x)

plot(prune.fit)
text(prune.fit)
```


```{r ROC-DT}
conf <- as.numeric(fit.predict[,2])
label <- (WAUS.test$CloudTomorrow)
tb <- as.tibble( cbind(conf,label))  %>% filter(!is.na(label))
pred <- prediction(tb$conf,tb$label)

perf<-performance(pred,"tpr","fpr")
plot(perf)
abline(0,1)
```


============================================ naive base

```{r NB}
NB.Model=naiveBayes(CloudTomorrow~.,data=WAUS.train)
NB.predict=predict(NB.Model,WAUS.test,type = "raw")
#x <- as.tibble(table(actual=WAUS.test$CloudTomorrow,predicted=NB.predict))
```
```{r roc-NB}
conf <- as.numeric(NB.predict[,2])
label <- as.numeric(WAUS.test$CloudTomorrow)
tb <- as.tibble( cbind(conf,label))  %>% filter(!is.na(label))
pred <- prediction(tb$conf,tb$label)

perf<-performance(pred,"tpr","fpr")
plot(perf)
abline(0,1)
```


Bagging V2
```{r include=F}
library(caret)  #for training and cross validation (also calls other model libaries)

## Warning: Installed Rcpp (0.12.13) different from Rcpp used to build dplyr (0.12.11).
## Please reinstall dplyr to avoid random crashes or undefined behavior.

library(rpart)  #for trees
#library(rattle)    # Fancy tree plot This is a difficult library to install (https://gist.github.com/zhiyzuo/a489ffdcc5da87f28f8589a55aa206dd) 
library(rpart.plot)             # Enhanced tree plots
library(RColorBrewer)       # Color selection for fancy tree plot
library(party)                  # Alternative decision tree algorithm
library(partykit)               # Convert rpart object to BinaryTree
library(pROC)   #for ROC curves

```

```{r DT}

#setting up cross-validation
cvcontrol <- trainControl(method="repeatedcv", number = 10,
                          allowParallel=TRUE)

train.tree <- train(CloudTomorrow ~ ., 
                   data=WAUS.train,
                   method="ctree",
                   trControl=cvcontrol,
                   tuneLength = 10,
                   na.action=na.pass)

plot(train.tree$finalModel)


#To evalaute the accuracy of the tree we can look at the confusion matrix for the Training data. 
#obtaining class predictions
tree.classTrain <-  predict(train.tree, 
                          type="raw")
#confusion matrix 
confusionMatrix(as.factor(WAUS.train$CloudTomorrow), as.factor(tree.classTrain))

#test the data
tree.probs=predict(train.tree,
                 newdata=WAUS.test,
                 type="prob")
#Calculate ROC curve
rocCurve.tree <- roc(WAUS.test$CloudTomorrow,tree.probs[,2])
#plot the ROC curve
plot(rocCurve.tree,col=c(4))

#calculate the area under curve (bigger is better)
auc(rocCurve.tree)
```
```{r DT}
#Using treebag 
train.bagg <- train(CloudTomorrow ~ ., 
                   data=WAUS.train,
                   method="treebag",
                   trControl=cvcontrol,
                   importance=TRUE)


plot(varImp(train.bagg))

#obtaining class predictions
bagg.classTrain <-  predict(train.bagg, 
                          type="raw")
head(bagg.classTrain)

confusionMatrix(WAUS.train$CloudTomorrow,bagg.classTrain)




#obtaining class predictions
bagg.classTest <-  predict(train.bagg, 
                         newdata = WAUS.test,
                          type="raw")
head(bagg.classTest)
#computing confusion matrix
confusionMatrix(WAUS.test$CloudTomorrow,bagg.classTest)


#Obtaining predicted probabilites for Test data
bagg.probs=predict(train.bagg,
                 newdata=WAUS.test,
                 type="prob")
#Calculate ROC curve
rocCurve.bagg <- roc(WAUS.test$CloudTomorrow,bagg.probs[,2])
#plot the ROC curve
plot(rocCurve.bagg,col=c(6))
```


```{r Ramdom-forrest}
train.rf <- train(CloudTomorrow ~ ., 
                  data=WAUS.train,
                  method="rf",
                  trControl=cvcontrol,
                  #tuneLength = 3,
                  importance=TRUE)

#obtaining class predictions
rf.classTrain <-  predict(train.rf, 
                          type="raw")


#Obtaining predicted probabilites for Test data
rf.probs=predict(train.rf,
                 newdata=WAUS.test,
                 type="prob")

#Calculate ROC curve
rocCurve.rf <- roc(WAUS.test$CloudTomorrow,rf.probs[,2])
#plot the ROC curve
plot(rocCurve.rf,col=c(1))
#calculate the area under curve (bigger is better)
auc(rocCurve.rf)
```
```{r comparision}
plot(rocCurve.tree,col=c(4))
plot(rocCurve.bagg,add=TRUE,col=c(6)) # color magenta is bagg
plot(rocCurve.rf,add=TRUE,col=c(1)) # color black is rf
```



